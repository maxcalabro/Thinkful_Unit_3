{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We've talked about Random Forests. Now it's time to build one.\n",
    "\n",
    "Here we'll use data from Lending Club to predict the state of a loan given some information about it. You can find the dataset [here](https://www.lendingclub.com/info/download-data.action). We'll use 2015 data. ([Thinkful mirror](https://www.dropbox.com/s/m7z42lubaiory33/LoanStats3d.csv?dl=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcalabro/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Replace the path with the correct path for your data.\n",
    "y2015 = pd.read_csv(\n",
    "    'LoanStats3d.csv',\n",
    "    skipinitialspace=True,\n",
    "    header=1\n",
    ")\n",
    "\n",
    "# Note the warning about dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(y2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## The Blind Approach\n",
    "\n",
    "Now, as we've seen before, creating a model is the easy part. Let's try just using everything we've got and throwing it without much thought into a Random Forest. SKLearn requires the independent variables to be be numeric, and all we want is dummy variables so let's use `get_dummies` from Pandas and see what happens off of this kind of naive approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Did your kernel die? My kernel died.\n",
    "\n",
    "Guess it isn't always going to be that easy...\n",
    "\n",
    "Can you think of what went wrong?\n",
    "\n",
    "(You're going to have to reset your kernel and reload the column, BUT DON'T RUN THE MODEL AGAIN OR YOU'LL CRASH THE KERNEL AGAIN!)\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "Well, `get_dummies` can be a very memory intensive thing, particularly if data are typed poorly. We got a warning about that earlier. Mixed data types get converted to objects, and that could create huge problems. Our dataset is about 400,000 rows. If there's a bad type there its going to see 400,000 distinct values and try to create dummies for all of them. That's bad. Lets look at all our categorical variables and see how many distinct counts there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "421097\n",
      "term\n",
      "2\n",
      "int_rate\n",
      "110\n",
      "grade\n",
      "7\n",
      "sub_grade\n",
      "35\n",
      "emp_title\n",
      "120812\n",
      "emp_length\n",
      "12\n",
      "home_ownership\n",
      "4\n",
      "verification_status\n",
      "3\n",
      "issue_d\n",
      "12\n",
      "loan_status\n",
      "7\n",
      "pymnt_plan\n",
      "1\n",
      "url\n",
      "421095\n",
      "desc\n",
      "34\n",
      "purpose\n",
      "14\n",
      "title\n",
      "27\n",
      "zip_code\n",
      "914\n",
      "addr_state\n",
      "49\n",
      "earliest_cr_line\n",
      "668\n",
      "revol_util\n",
      "1211\n",
      "initial_list_status\n",
      "2\n",
      "last_pymnt_d\n",
      "25\n",
      "next_pymnt_d\n",
      "4\n",
      "last_credit_pull_d\n",
      "26\n",
      "application_type\n",
      "2\n",
      "verification_status_joint\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "categorical = y2015.select_dtypes(include=['object'])\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Well that right there is what's called a problem. Some of these have over a hundred thousand distinct types. Lets drop the ones with over 30 unique values, converting to numeric where it makes sense. In doing this there's a lot of code that gets written to just see if the numeric conversion makes sense. It's a manual process that we'll abstract away and just include the conversion.\n",
    "\n",
    "You could extract numeric features from the dates, but here we'll just drop them. There's a lot of data, it shouldn't be a huge problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert ID and Interest Rate to numeric.\n",
    "y2015['id'] = pd.to_numeric(y2015['id'], errors='coerce')\n",
    "y2015['int_rate'] = pd.to_numeric(y2015['int_rate'].str.strip('%'), errors='coerce')\n",
    "\n",
    "# Drop other columns with many unique variables\n",
    "y2015.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util',\n",
    "            'sub_grade', 'addr_state', 'desc'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonder what was causing the dtype error on the id column, which _should_ have all been integers? Let's look at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove two summary rows at the end that don't actually contain data.\n",
    "y2015 = y2015[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now this should be better. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(y2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "It finally works! We had to sacrifice sub grade, state address and description, but that's fine. If you want to include them you could run the dummies independently and then append them back to the dataframe.\n",
    "\n",
    "## Second Attempt\n",
    "\n",
    "Now let's try this model again.\n",
    "\n",
    "We're also going to drop NA columns, rather than impute, because our data is rich enough that we can probably get away with it.\n",
    "\n",
    "This model may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(rfc, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The score cross validation reports is the accuracy of the tree. Here we're about 98% accurate.\n",
    "\n",
    "That works pretty well, but there are a few potential problems. Firstly, we didn't really do much in the way of feature selection or model refinement. As such there are a lot of features in there that we don't really need. Some of them are actually quite impressively useless.\n",
    "\n",
    "There's also some variance in the scores. The fact that one gave us only 93% accuracy while others gave higher than 98 is concerning. This variance could be corrected by increasing the number of estimators. That will make it take even longer to run, however, and it is already quite slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRILL: Third Attempt\n",
    "\n",
    "So here's your task. Get rid of as much data as possible without dropping below an average of 90% accuracy in a 10-fold cross validation.\n",
    "\n",
    "You'll want to do a few things in this process. First, dive into the data that we have and see which features are most important. This can be the raw features or the generated dummies. You may want to use PCA or correlation matrices.\n",
    "\n",
    "Can you do it without using anything related to payment amount or outstanding principal? How do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_frac = corrmat.sample(frac=.02).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>last_credit_pull_d_Nov-2016</th>\n",
       "      <th>last_credit_pull_d_Oct-2015</th>\n",
       "      <th>last_credit_pull_d_Oct-2016</th>\n",
       "      <th>last_credit_pull_d_Sep-2015</th>\n",
       "      <th>last_credit_pull_d_Sep-2016</th>\n",
       "      <th>application_type_INDIVIDUAL</th>\n",
       "      <th>application_type_JOINT</th>\n",
       "      <th>verification_status_joint_Not Verified</th>\n",
       "      <th>verification_status_joint_Source Verified</th>\n",
       "      <th>verification_status_joint_Verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>-0.012517</td>\n",
       "      <td>-0.060417</td>\n",
       "      <td>-0.018473</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.016947</td>\n",
       "      <td>-0.080718</td>\n",
       "      <td>-0.032915</td>\n",
       "      <td>-0.007227</td>\n",
       "      <td>-0.041079</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>0.031287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_id</th>\n",
       "      <td>0.998797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>-0.012228</td>\n",
       "      <td>-0.060822</td>\n",
       "      <td>-0.017985</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020688</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>-0.080442</td>\n",
       "      <td>-0.032882</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>-0.041347</td>\n",
       "      <td>0.041347</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>-0.012244</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.144798</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>-0.038436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>-0.012244</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.144798</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>-0.038436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>-0.012517</td>\n",
       "      <td>-0.012228</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144463</td>\n",
       "      <td>0.942541</td>\n",
       "      <td>0.403280</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>-0.038474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>-0.004571</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "id               1.000000   0.998797  -0.012244    -0.012244        -0.012517   \n",
       "member_id        0.998797   1.000000  -0.011956    -0.011956        -0.012228   \n",
       "loan_amnt       -0.012244  -0.011956   1.000000     1.000000         0.999994   \n",
       "funded_amnt     -0.012244  -0.011956   1.000000     1.000000         0.999994   \n",
       "funded_amnt_inv -0.012517  -0.012228   0.999994     0.999994         1.000000   \n",
       "\n",
       "                 int_rate  installment  annual_inc       dti  delinq_2yrs  \\\n",
       "id              -0.060417    -0.018473   -0.000723  0.014566    -0.000913   \n",
       "member_id       -0.060822    -0.017985   -0.000284  0.013992    -0.000786   \n",
       "loan_amnt        0.144798     0.942555    0.403188  0.016611    -0.038436   \n",
       "funded_amnt      0.144798     0.942555    0.403188  0.016611    -0.038436   \n",
       "funded_amnt_inv  0.144463     0.942541    0.403280  0.016448    -0.038474   \n",
       "\n",
       "                                ...                  \\\n",
       "id                              ...                   \n",
       "member_id                       ...                   \n",
       "loan_amnt                       ...                   \n",
       "funded_amnt                     ...                   \n",
       "funded_amnt_inv                 ...                   \n",
       "\n",
       "                 last_credit_pull_d_Nov-2016  last_credit_pull_d_Oct-2015  \\\n",
       "id                                 -0.021035                    -0.016947   \n",
       "member_id                          -0.020688                    -0.017055   \n",
       "loan_amnt                           0.010823                     0.016994   \n",
       "funded_amnt                         0.010823                     0.016994   \n",
       "funded_amnt_inv                     0.010859                     0.017003   \n",
       "\n",
       "                 last_credit_pull_d_Oct-2016  last_credit_pull_d_Sep-2015  \\\n",
       "id                                 -0.080718                    -0.032915   \n",
       "member_id                          -0.080442                    -0.032882   \n",
       "loan_amnt                           0.018812                     0.007634   \n",
       "funded_amnt                         0.018812                     0.007634   \n",
       "funded_amnt_inv                     0.018756                     0.007669   \n",
       "\n",
       "                 last_credit_pull_d_Sep-2016  application_type_INDIVIDUAL  \\\n",
       "id                                 -0.007227                    -0.041079   \n",
       "member_id                          -0.007275                    -0.041347   \n",
       "loan_amnt                          -0.004603                    -0.035878   \n",
       "funded_amnt                        -0.004603                    -0.035878   \n",
       "funded_amnt_inv                    -0.004571                    -0.035787   \n",
       "\n",
       "                 application_type_JOINT  \\\n",
       "id                             0.041079   \n",
       "member_id                      0.041347   \n",
       "loan_amnt                      0.035878   \n",
       "funded_amnt                    0.035878   \n",
       "funded_amnt_inv                0.035787   \n",
       "\n",
       "                 verification_status_joint_Not Verified  \\\n",
       "id                                             0.031287   \n",
       "member_id                                      0.031460   \n",
       "loan_amnt                                      0.007625   \n",
       "funded_amnt                                    0.007625   \n",
       "funded_amnt_inv                                0.007631   \n",
       "\n",
       "                 verification_status_joint_Source Verified  \\\n",
       "id                                                     NaN   \n",
       "member_id                                              NaN   \n",
       "loan_amnt                                              NaN   \n",
       "funded_amnt                                            NaN   \n",
       "funded_amnt_inv                                        NaN   \n",
       "\n",
       "                 verification_status_joint_Verified  \n",
       "id                                         0.026791  \n",
       "member_id                                  0.026996  \n",
       "loan_amnt                                  0.043100  \n",
       "funded_amnt                                0.043100  \n",
       "funded_amnt_inv                            0.042964  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_frac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these columns are highly correlated to each other, but I'm not sure how to pick out the worst offenders... Let's first get rid of more of the columns with high number of possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.drop(['title', 'last_credit_pull_d'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "2\n",
      "grade\n",
      "7\n",
      "emp_length\n",
      "12\n",
      "home_ownership\n",
      "4\n",
      "verification_status\n",
      "3\n",
      "issue_d\n",
      "12\n",
      "loan_status\n",
      "7\n",
      "pymnt_plan\n",
      "1\n",
      "purpose\n",
      "14\n",
      "initial_list_status\n",
      "2\n",
      "last_pymnt_d\n",
      "25\n",
      "next_pymnt_d\n",
      "4\n",
      "application_type\n",
      "2\n",
      "verification_status_joint\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "categorical = y2015.select_dtypes(include=['object'])\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.drop(['last_pymnt_d'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.drop(['issue_d', 'purpose', 'emp_length'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 86)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>next_pymnt_d_Feb-2017</th>\n",
       "      <th>next_pymnt_d_Jan-2017</th>\n",
       "      <th>next_pymnt_d_Jul-2016</th>\n",
       "      <th>next_pymnt_d_Mar-2017</th>\n",
       "      <th>application_type_INDIVIDUAL</th>\n",
       "      <th>application_type_JOINT</th>\n",
       "      <th>verification_status_joint_Not Verified</th>\n",
       "      <th>verification_status_joint_Source Verified</th>\n",
       "      <th>verification_status_joint_Verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68009401.0</td>\n",
       "      <td>72868139.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>14.85</td>\n",
       "      <td>379.39</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>33.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68354783.0</td>\n",
       "      <td>73244544.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>7.49</td>\n",
       "      <td>298.58</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>22.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68466916.0</td>\n",
       "      <td>73356753.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>7.49</td>\n",
       "      <td>777.55</td>\n",
       "      <td>109000.0</td>\n",
       "      <td>26.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68466961.0</td>\n",
       "      <td>73356799.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6.49</td>\n",
       "      <td>858.05</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>21.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68495092.0</td>\n",
       "      <td>73384866.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>19.89</td>\n",
       "      <td>320.99</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>25.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   member_id  loan_amnt  funded_amnt  funded_amnt_inv  int_rate  \\\n",
       "0  68009401.0  72868139.0    16000.0      16000.0          16000.0     14.85   \n",
       "1  68354783.0  73244544.0     9600.0       9600.0           9600.0      7.49   \n",
       "2  68466916.0  73356753.0    25000.0      25000.0          25000.0      7.49   \n",
       "3  68466961.0  73356799.0    28000.0      28000.0          28000.0      6.49   \n",
       "4  68495092.0  73384866.0     8650.0       8650.0           8650.0     19.89   \n",
       "\n",
       "   installment  annual_inc    dti  delinq_2yrs  \\\n",
       "0       379.39     48000.0  33.18          0.0   \n",
       "1       298.58     60000.0  22.44          0.0   \n",
       "2       777.55    109000.0  26.02          0.0   \n",
       "3       858.05     92000.0  21.60          0.0   \n",
       "4       320.99     55000.0  25.49          0.0   \n",
       "\n",
       "                  ...                  initial_list_status_w  \\\n",
       "0                 ...                                      1   \n",
       "1                 ...                                      1   \n",
       "2                 ...                                      1   \n",
       "3                 ...                                      1   \n",
       "4                 ...                                      1   \n",
       "\n",
       "   next_pymnt_d_Feb-2017  next_pymnt_d_Jan-2017  next_pymnt_d_Jul-2016  \\\n",
       "0                      0                      1                      0   \n",
       "1                      0                      1                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      1                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   next_pymnt_d_Mar-2017  application_type_INDIVIDUAL  application_type_JOINT  \\\n",
       "0                      0                            1                       0   \n",
       "1                      0                            1                       0   \n",
       "2                      0                            1                       0   \n",
       "3                      0                            1                       0   \n",
       "4                      0                            1                       0   \n",
       "\n",
       "   verification_status_joint_Not Verified  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   verification_status_joint_Source Verified  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   verification_status_joint_Verified  \n",
       "0                                   0  \n",
       "1                                   0  \n",
       "2                                   0  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2015.drop(['id', 'member_id', 'loan_amnt'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 83)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rfc, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 94)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment',\n",
       "       'grade', 'home_ownership', 'annual_inc', 'verification_status',\n",
       "       'loan_status', 'pymnt_plan', 'dti', 'delinq_2yrs', 'inq_last_6mths',\n",
       "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc',\n",
       "       'pub_rec', 'revol_bal', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
       "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
       "       'collection_recovery_fee', 'last_pymnt_amnt', 'next_pymnt_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint',\n",
       "       'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
       "       'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m',\n",
       "       'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',\n",
       "       'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util',\n",
       "       'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
       "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
       "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
       "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq',\n",
       "       'mths_since_recent_inq', 'mths_since_recent_revol_delinq',\n",
       "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
       "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
       "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
       "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
       "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
       "       'total_il_high_credit_limit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89, 32, 85, 21, 12, 82, 31,  2, 42, 52, 27, 62,  3, 87, 17, 79, 47,\n",
       "       37,  5,  1, 80,  4, 84, 15, 74, 70, 72, 28, 24, 50, 40, 23, 73, 39,\n",
       "       36, 16, 91,  7, 81,  9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = np.random.choice(len(X.columns), 40, replace=False)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(X.columns[cols],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 53)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to just remove a whole bunch of variables at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9606991 ,  0.95991546,  0.95996296,  0.95979673,  0.95946331,\n",
       "        0.95943956,  0.95993731,  0.95891615,  0.95915168,  0.95855698])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, dropping 40 rows didn't decrease our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple = X.loc[:,['funded_amnt', 'total_pymnt', 'last_pymnt_amnt', 'delinq_amnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72543991,  0.9141317 ,  0.8814799 ,  0.91199449,  0.90945144,\n",
       "        0.89724531,  0.8693391 ,  0.89351445,  0.90737882,  0.9112478 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_simple, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally got below 90! Let's add a few more colums and see if we can recover some of that accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amnt', 'dti', 'delinq_2yrs', 'total_acc', 'out_prncp',\n",
       "       'total_pymnt', 'total_rec_int', 'total_rec_late_fee', 'last_pymnt_amnt',\n",
       "       'policy_code', 'acc_now_delinq', 'acc_open_past_24mths', 'avg_cur_bal',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_rev_tl_op',\n",
       "       'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc',\n",
       "       'num_accts_ever_120_pd', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_tl_90g_dpd_24m', 'tax_liens', 'total_bal_ex_mort',\n",
       "       'total_il_high_credit_limit', 'home_ownership_ANY',\n",
       "       'home_ownership_MORTGAGE', 'home_ownership_OWN', 'home_ownership_RENT',\n",
       "       'verification_status_Not Verified',\n",
       "       'verification_status_Source Verified', 'verification_status_Verified',\n",
       "       'initial_list_status_f', 'initial_list_status_w',\n",
       "       'next_pymnt_d_Feb-2017', 'next_pymnt_d_Jan-2017',\n",
       "       'next_pymnt_d_Jul-2016', 'next_pymnt_d_Mar-2017',\n",
       "       'application_type_INDIVIDUAL', 'application_type_JOINT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_simple = y2015.loc[:,['funded_amnt', 'total_pymnt', 'last_pymnt_amnt', 'delinq_amnt', 'home_ownership', 'verification_status', 'mths_since_last_delinq']]\n",
    "\n",
    "X_simple = pd.get_dummies(X_simple)\n",
    "X_simple = X_simple.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73534231,  0.92201563,  0.9118995 ,  0.91199449,  0.90771788,\n",
       "        0.90465448,  0.89721912,  0.90629082,  0.91319733,  0.9084216 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_simple, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right around around 90% accuracy, although the .73 group suggests we're missing something. But we only have 7 of the original variables, which is pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
