{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Text From Amazon Reviews to Predict Ratings\n",
    "\n",
    "Here we'll look at the text in a review and see if we can predict whether the review is positive (4 or 5 of 5) or negative (1, 2, or 3 of 5). We'll use Scikit Learn's NLP method Tfidf to extract features.\n",
    "\n",
    "Note that part of this notebook has been run with previous parameters for our feature search -- ngram_range=(1,1) and min_df=5, rather than the current version of ngram_range=(1,3) and min_df=20. We'll discuss differences in the results in the conclusion, but the change did slightly improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "        \n",
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "    return pd.DataFrame.from_dict(df, orient='index') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64706, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = getDF('reviews_Digital_Music_5.json.gz')\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A3EBHHCZO6V2A4  5555991584  Amaranth \"music fan\"  [3, 3]   \n",
       "1   AZPWAXJG9OJXV  5555991584             bethtexas  [0, 0]   \n",
       "2  A38IRL0X2T4DPF  5555991584           bob turnley  [2, 2]   \n",
       "3  A22IK3I6U76GX0  5555991584                 Calle  [1, 1]   \n",
       "4  A1AISPOIIHTHXX  5555991584           Cloud \"...\"  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...      5.0   \n",
       "1  A clasically-styled and introverted album, Mem...      5.0   \n",
       "2  I never thought Enya would reach the sublime h...      5.0   \n",
       "3  This is the third review of an irish album I w...      5.0   \n",
       "4  Enya, despite being a successful recording art...      4.0   \n",
       "\n",
       "                        summary  unixReviewTime   reviewTime  \n",
       "0       Enya's last great album      1158019200  09 12, 2006  \n",
       "1      Enya at her most elegant       991526400   06 3, 2001  \n",
       "2               The best so far      1058140800  07 14, 2003  \n",
       "3  Ireland produces good music.       957312000   05 3, 2000  \n",
       "4        4.5; music to dream to      1200528000  01 17, 2008  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    64706.000000\n",
       "mean         4.222514\n",
       "std          1.086081\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12590"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_data['overall']<4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll set our classification threshold at 4: 4's and 5's will be positive, lower will be negative.\n",
    "\n",
    "raw_data['outcome_var'] = np.where(raw_data['overall']<4, 0, 1)\n",
    "data_clean = raw_data[['reviewText', 'outcome_var']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing shapes:\n",
      "(45294, 2) (19412, 2)\n",
      "Positive and negative outcome counts in training set:\n",
      "36453 8841\n",
      "Length of training set after resampling:\n",
      "72906\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "data_train, data_test = train_test_split(data_clean, test_size=0.3, random_state=100)\n",
    "print('Training and testing shapes:')\n",
    "print(data_train.shape, data_test.shape)\n",
    "print('Positive and negative outcome counts in training set:')\n",
    "print(len(data_train[data_train['outcome_var']==1]), len(data_train[data_train['outcome_var']==0]))\n",
    "\n",
    "# Resample the training data to increase the number of negative examples\n",
    "train_pos = data_train[data_train['outcome_var']==1]\n",
    "train_neg = data_train[data_train['outcome_var']==0]\n",
    "train_neg = resample(train_neg, n_samples=len(train_pos))\n",
    "data_train_resamp = pd.concat([train_pos, train_neg]).sample(frac=1)\n",
    "print('Length of training set after resampling:')\n",
    "print(len(data_train_resamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words='english',\n",
    "                        ngram_range=(1, 3), \n",
    "                        analyzer='word', \n",
    "                        min_df=20,\n",
    "                        max_features=None, \n",
    "                        vocabulary=None, \n",
    "                        binary=False, \n",
    "                        use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape:\n",
      "(72906, 52079)\n",
      "X_test Shape:\n",
      "(19412, 52079)\n"
     ]
    }
   ],
   "source": [
    "tfidf.fit(data_train_resamp.reviewText)\n",
    "X_train = tfidf.transform(data_train_resamp.reviewText)\n",
    "Y_train = data_train_resamp.outcome_var\n",
    "\n",
    "X_test = tfidf.transform(data_test.reviewText)\n",
    "Y_test = data_test.outcome_var\n",
    "\n",
    "print('X_train Shape:')\n",
    "print(X_train.get_shape())\n",
    "print('X_test Shape:')\n",
    "print(X_test.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Shape:\n",
      "(72906, 1000)\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=1000)\n",
    "svd.fit(X_train)\n",
    "X_train_svd = svd.transform(X_train)\n",
    "X_test_svd = svd.transform(X_test)\n",
    "print('SVD Shape:')\n",
    "print(X_train_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auprc(Y, Y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(Y, Y_pred)\n",
    "    return auc(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82327527  0.8176519   0.81724043  0.82290809  0.821262  ]\n",
      "[[ 2116  1633]\n",
      " [ 4105 11558]]\n",
      "AUPRC: 0.105921957443\n"
     ]
    }
   ],
   "source": [
    "# Using full dataset -- 36000 features\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_features=None, max_depth=32)\n",
    "dtc.fit(X_train, Y_train)\n",
    "Y_pred = dtc.predict(X_test)\n",
    "print(cross_val_score(dtc, X_train, Y_train, cv=5))\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8920587   0.88670964  0.8920587   0.88806584  0.89218107]\n",
      "[[ 1252  2497]\n",
      " [ 2505 13158]]\n",
      "AUPRC: 0.0979335051142\n"
     ]
    }
   ],
   "source": [
    "# Using SVD with 1000 components\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_features=None, max_depth=32)\n",
    "dtc.fit(X_train_svd, Y_train)\n",
    "Y_pred = dtc.predict(X_test_svd)\n",
    "print(cross_val_score(dtc, X_train_svd, Y_train, cv=5))\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=30,\n",
       "            max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [4, 8, 16, 32], 'max_features': [4, 10, 'sqrt', None], 'min_samples_split': [2, 8, 32]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_params = {'max_depth':[4, 8, 16, 32],\n",
    "              'max_features':[4, 10, 'sqrt', None],\n",
    "              'min_samples_split':[2, 8, 32]}\n",
    "dtc_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=dtc_params)\n",
    "dtc_grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813938496146\n",
      "{'max_depth': 32, 'max_features': None, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dtc_grid.best_score_)\n",
    "print(dtc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2280  1469]\n",
      " [ 1876 13787]]\n",
      "AUPRC: 0.133417239986\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=64, max_depth=32, min_samples_split=8)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [4, 8, 16, 32], 'n_estimators': [8, 16, 32, 64], 'min_samples_split': [2, 8, 32]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_params = {'max_depth':[4, 8, 16, 32],\n",
    "              'n_estimators':[8, 16, 32, 64],\n",
    "              'min_samples_split':[2, 8, 32]}\n",
    "rfc_grid = GridSearchCV(RandomForestClassifier(), param_grid=rfc_params)\n",
    "rfc_grid.fit(X_train_svd, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params for RFC are: max_depth=32, min_samples_split=8, n_estimators=64. With this we're getting an AUPRC of 0.132. Confusion matrix is: \n",
    "\n",
    "[[ 2129  1620]\n",
    "\n",
    "[ 1600 14063]]\n",
    "\n",
    "So at least our true negatives are greater than false negatives or false positives! Better than most of our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963158039119\n",
      "{'max_depth': 32, 'min_samples_split': 8, 'n_estimators': 64}\n"
     ]
    }
   ],
   "source": [
    "print(rfc_grid.best_score_)\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAECCAYAAADwwjbkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1092987f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[:1000]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.title(\"Top {} Feature Importances\".format(len(top_indices)))\n",
    "plt.bar(range(len(top_indices)), importances[top_indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xlim([-1, len(top_indices)])\n",
    "plt.ylabel('% Variance Described')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained with 100 features: 0.3211160692062343\n",
      "Variance explained with 200 features: 0.4126542795724461\n",
      "Variance explained with 500 features: 0.5341381243188429\n",
      "Variance explained with 1000 features: 0.6284265258986561\n",
      "Variance explained with 2000 features: 0.7243891957777864\n",
      "Variance explained with 5000 features: 0.8450331053479401\n",
      "Variance explained with 10000 features: 0.9349523739086338\n",
      "Variance explained with 20000 features: 0.9988838145768447\n",
      "Total Features: 52079\n"
     ]
    }
   ],
   "source": [
    "for n_idx in [100, 200, 500, 1000, 2000, 5000, 10000, 20000]:\n",
    "    print('Variance explained with {} features: {}'.format(n_idx, importances[indices[:n_idx]].sum()))\n",
    "print('Total Features: ' + str(len(indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance appears to drop off dramatically after the first 500 features, but the tail is long enough that lower importances still play a large role in the variance of the model. But remember -- we started with 52,000 features, so even dropping down to 5,000 is a significant reduction. All features after 20,000 have essentially zero importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72906, 5000) (19412, 5000)\n",
      "(72906, 20000) (19412, 20000)\n"
     ]
    }
   ],
   "source": [
    "n_indices = 5000\n",
    "X_train_rfc = X_train[:, indices[:n_indices]]\n",
    "X_test_rfc = X_test[:, indices[:n_indices]]\n",
    "print(X_train_rfc.shape, X_test_rfc.shape)\n",
    "\n",
    "n_indices = 20000\n",
    "X_train_full = X_train[:, indices[:n_indices]]\n",
    "X_test_full = X_test[:, indices[:n_indices]]\n",
    "print(X_train_full.shape, X_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2148  1601]\n",
      " [ 1751 13912]]\n",
      "AUPRC: 0.130730987486\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=64, max_depth=32, min_samples_split=8)\n",
    "rfc.fit(X_train_rfc, Y_train)\n",
    "Y_pred = rfc.predict(X_test_rfc)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86174736  0.86737073  0.86236456  0.86591221  0.86769547]\n",
      "[[ 2797   952]\n",
      " [ 2157 13506]]\n",
      "AUPRC: 0.146906889434\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression(penalty='l2', C=.65, fit_intercept=True)\n",
    "lgr.fit(X_train, Y_train)\n",
    "print(cross_val_score(lgr, X_train, Y_train, cv=5))\n",
    "Y_pred = lgr.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with all that RFC tuning, logistic regression runs better than random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beware -- slow to run. Use fewer features.\n",
    "knc = KNeighborsClassifier(n_neighbors=3)\n",
    "knc.fit(X_train_rfc, Y_train)\n",
    "Y_pred = knc.predict(X_test_rfc)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77842546  0.77287066  0.7826087   0.78196159  0.78744856]\n",
      "[[ 2809   940]\n",
      " [ 4666 10997]]\n",
      "AUPRC: 0.124988222709\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "Y_pred = bnb.predict(X_test)\n",
    "print(cross_val_score(bnb, X_train, Y_train, cv=5))\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 356   16]\n",
      " [1899  808]]\n",
      "AUPRC: 0.0687317577271\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2724  1025]\n",
      " [ 3683 11980]]\n",
      "AUPRC: 0.131013974112\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=4)\n",
    "gbc.fit(X_train_full, Y_train)\n",
    "Y_pred = gbc.predict(X_test_full)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [12, 24], 'n_estimators': [50, 100], 'learning_rate': [0.1, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_params = {'max_depth':[12, 24],\n",
    "              'n_estimators':[50, 100],\n",
    "              'learning_rate':[0.1, 0.3]}\n",
    "gbc_grid = GridSearchCV(GradientBoostingClassifier(), param_grid=gbc_params, scoring='average_precision')\n",
    "gbc_grid.fit(X_train_rfc, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937523619882\n",
      "{'learning_rate': 0.1, 'max_depth': 12, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(gbc_grid.best_score_)\n",
    "print(gbc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2280  1469]\n",
      " [ 1876 13787]]\n",
      "AUPRC: 0.133417239986\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=64, max_depth=32, min_samples_split=8)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82768390686173499"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88108627  0.88142916  0.88108627  0.88408779  0.87969822]\n",
      "[[ 2772   977]\n",
      " [ 1949 13714]]\n",
      "AUPRC: 0.147860529058\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression(penalty='l2', C=.65, fit_intercept=True)\n",
    "lgr.fit(X_train, Y_train)\n",
    "print(cross_val_score(lgr, X_train, Y_train, cv=5))\n",
    "Y_pred = lgr.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84926849371522772"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Well, we're doing okay, maybe even pretty good. The accuracy of our model is slightly better than guessing only the more common class (acc = 0.85), however, we have a lot of false positives and false negatives. It turns out logistic regression actually performed best, slightly beating out random forest and gradient boosting, both of which are significantly slower to run. \n",
    "\n",
    "Initially, we ran the feature creation using ngram_range=(1,1), which only selects one-word phrases, and min_df=5, which means we'll use them even if they're fairly rare in the data set. I switched the parameters to ngram_range=(1,3) and min_df=20, which means we'll use up to 3-word phrases, but they have to be slightly more common in the data set to make the cut. This brought our raw feature set from 36,000 to 52,000, and slightly increased our accuracy. I may be able to increase performance even more by reducing min_df, but that would also inflate our feature set and slow down processing. A project for a faster machine. \n",
    "\n",
    "Other notable bits from our modeling: KNN took forever to run, I suspect because of the large number of features. SVC did terribly. I wonder if logistic regression did better than random forest because of the large feature set as well. There are so many possible choices a decision tree could be making that it can only choose the few that are most effective. Regression, on the other hand, fits every feature quickly. \n",
    "\n",
    "I used one of the smaller sets of Amazon reviews to go easy on my processor, but I suspect we could do even better on a larger set (this one had 64,000 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
