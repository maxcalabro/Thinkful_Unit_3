{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "        \n",
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "    return pd.DataFrame.from_dict(df, orient='index') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64706, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = getDF('reviews_Digital_Music_5.json.gz')\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A3EBHHCZO6V2A4  5555991584  Amaranth \"music fan\"  [3, 3]   \n",
       "1   AZPWAXJG9OJXV  5555991584             bethtexas  [0, 0]   \n",
       "2  A38IRL0X2T4DPF  5555991584           bob turnley  [2, 2]   \n",
       "3  A22IK3I6U76GX0  5555991584                 Calle  [1, 1]   \n",
       "4  A1AISPOIIHTHXX  5555991584           Cloud \"...\"  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...      5.0   \n",
       "1  A clasically-styled and introverted album, Mem...      5.0   \n",
       "2  I never thought Enya would reach the sublime h...      5.0   \n",
       "3  This is the third review of an irish album I w...      5.0   \n",
       "4  Enya, despite being a successful recording art...      4.0   \n",
       "\n",
       "                        summary  unixReviewTime   reviewTime  \n",
       "0       Enya's last great album      1158019200  09 12, 2006  \n",
       "1      Enya at her most elegant       991526400   06 3, 2001  \n",
       "2               The best so far      1058140800  07 14, 2003  \n",
       "3  Ireland produces good music.       957312000   05 3, 2000  \n",
       "4        4.5; music to dream to      1200528000  01 17, 2008  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    64706.000000\n",
       "mean         4.222514\n",
       "std          1.086081\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12590"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_data['overall']<4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll set our classification threshold at 4: 4's and 5's will be positive, lower will be negative.\n",
    "\n",
    "raw_data['outcome_var'] = np.where(raw_data['overall']<4, 0, 1)\n",
    "reviews = [x for x in raw_data['reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words='english',\n",
    "                        ngram_range=(1, 1), \n",
    "                        analyzer='word', \n",
    "                        min_df=5,\n",
    "                        max_features=None, \n",
    "                        vocabulary=None, \n",
    "                        binary=False, \n",
    "                        use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape:\n",
      "(64706, 32184)\n",
      "SVD Shape:\n",
      "(64706, 200)\n"
     ]
    }
   ],
   "source": [
    "tfidf.fit(reviews)\n",
    "word_counts = tfidf.transform(reviews)\n",
    "print('Original Shape:')\n",
    "print(word_counts.get_shape())\n",
    "\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "word_svd = svd.fit_transform(word_counts)\n",
    "print('SVD Shape:')\n",
    "print(word_svd.shape)\n",
    "\n",
    "pos_idx = np.where(raw_data['outcome_var']==1)[0]\n",
    "neg_idx = np.where(raw_data['outcome_var']==0)[0]\n",
    "pos_counts = word_svd[pos_idx]\n",
    "neg_counts = word_svd[neg_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train neg and pos shapes:\n",
      "(41692, 200) (41692, 200)\n",
      "Y_train neg and pos shapes:\n",
      "(41692,) (41692,)\n",
      "X_test neg and pos shapes:\n",
      "(2518, 200) (10424, 200)\n",
      "Y_train neg and pos shapes:\n",
      "(2518,) (10424,)\n"
     ]
    }
   ],
   "source": [
    "n_test = 0.2\n",
    "\n",
    "X_train_pos, X_test_pos = train_test_split(pos_counts, test_size=n_test, random_state=0)\n",
    "X_train_neg, X_test_neg = train_test_split(neg_counts, test_size=n_test, random_state=0)\n",
    "Y_train_pos, Y_test_pos = train_test_split(raw_data['outcome_var'][pos_idx], test_size=n_test, random_state=0)\n",
    "Y_train_neg, Y_test_neg = train_test_split(raw_data['outcome_var'][neg_idx], test_size=n_test, random_state=0)\n",
    "\n",
    "X_train_neg_resamp = resample(X_train_neg, n_samples=len(X_train_pos))\n",
    "print('X_train neg and pos shapes:')\n",
    "print(X_train_neg_resamp.shape, X_train_pos.shape)\n",
    "\n",
    "Y_train_neg_resamp = resample(Y_train_neg, n_samples=len(Y_train_pos))\n",
    "print('Y_train neg and pos shapes:')\n",
    "print(Y_train_neg_resamp.shape, Y_train_pos.shape)\n",
    "\n",
    "print('X_test neg and pos shapes:')\n",
    "print(X_test_neg.shape, X_test_pos.shape)\n",
    "\n",
    "print('Y_train neg and pos shapes:')\n",
    "print(Y_test_neg.shape, Y_test_pos.shape)\n",
    "\n",
    "X_train = np.concatenate([X_train_pos, X_train_neg_resamp])\n",
    "X_test = np.concatenate([X_test_pos, X_test_neg])\n",
    "Y_train = np.concatenate([Y_train_pos, Y_train_neg_resamp])\n",
    "Y_test = np.concatenate([Y_test_pos, Y_test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auprc(Y, Y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(Y, Y_pred)\n",
    "    return auc(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1107 1411]\n",
      " [3061 7363]]\n",
      "AUPRC: 0.0855860705542\n",
      "[[ 898 1620]\n",
      " [2430 7994]]\n",
      "AUPRC: 0.0876306600745\n",
      "[[ 977 1541]\n",
      " [2610 7814]]\n",
      "AUPRC: 0.0878406005207\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_features=4, max_depth=20)\n",
    "dtc.fit(X_train, Y_train)\n",
    "Y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))\n",
    "\n",
    "dtc.fit(X_train, Y_train)\n",
    "Y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))\n",
    "\n",
    "dtc.fit(X_train, Y_train)\n",
    "Y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 669 1849]\n",
      " [ 508 9916]]\n",
      "AUPRC: 0.111238988731\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=30, max_depth=20)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1955  563]\n",
      " [2502 7922]]\n",
      "AUPRC: 0.13803467158\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train, Y_train)\n",
    "Y_pred = lgr.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  74  298]\n",
      " [ 390 2317]]\n",
      "AUPRC: 0.0551362671706\n"
     ]
    }
   ],
   "source": [
    "# Beware -- slow to run.\n",
    "knc = KNeighborsClassifier(n_neighbors=3)\n",
    "knc.fit(X_train, Y_train)\n",
    "Y_pred = knc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1764  754]\n",
      " [2719 7705]]\n",
      "AUPRC: 0.124617834148\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "Y_pred = bnb.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 356   16]\n",
      " [1899  808]]\n",
      "AUPRC: 0.0687317577271\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 179  193]\n",
      " [ 414 2293]]\n",
      "AUPRC: 0.0727622750216\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=4)\n",
    "gbc.fit(X_train, Y_train)\n",
    "Y_pred = gbc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
