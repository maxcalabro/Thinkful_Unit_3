{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAEWCAYAAAAEtVmdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvMwVMqSRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109436e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the data wasn't shuffled, so all of the original test set was likely from a country that wasn't in the training set. Let's start there. Let's also add a couple features that combine the variables that are most influencial from our initial attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcalabro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/maxcalabro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "X['age_happy'] = X['agea'] * X['happy']\n",
    "X['age/tvtot'] = X['agea'] // (X['tvtot'] + 1)\n",
    "#X['meet_fair'] = X['pplfair'] * X['sclmeet']\n",
    "#X['trst_act'] = X['ppltrst'] * X['sclact']\n",
    "#X['meet_fair_help'] = X['sclmeet'] * X['pplfair'] * X['pplhlp']\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model with only those two changes improves accuracy on the test set by about 1/2 a percent. Let's tweak the model and see what changes allow us to do even better.\n",
    "\n",
    "    Test set accuracy:\n",
    "    Percent Type I errors: 0.06012269938650307\n",
    "    Percent Type II errors: 0.18159509202453988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0463720676486634\n",
      "Percent Type II errors: 0.1723949809056192\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05766871165644172\n",
      "Percent Type II errors: 0.1656441717791411\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance',\n",
    "          'learning_rate': 0.1,\n",
    "          'min_samples_split': 20,\n",
    "          'subsample':1}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Baseline: \n",
    "\n",
    "    Test set accuracy:\n",
    "    Percent Type I errors: 0.06257668711656442\n",
    "    Percent Type II errors: 0.18527607361963191\n",
    "\n",
    "With Shuffle + Three new features: (New baseline)\n",
    "\n",
    "    Percent Type I errors: 0.06012269938650307\n",
    "    Percent Type II errors: 0.18159509202453988\n",
    "    \n",
    "max_depth=3: (overfit - got worse)\n",
    "\n",
    "    Percent Type I errors: 0.08220858895705521\n",
    "    Percent Type II errors: 0.18282208588957055\n",
    "    \n",
    "estimators=700: (moved Type II errors to Type I)\n",
    "\n",
    "    Percent Type I errors: 0.06134969325153374\n",
    "    Percent Type II errors: 0.17914110429447852\n",
    "    \n",
    "loss='exponential': (got worse)\n",
    "\n",
    "    Percent Type I errors: 0.06257668711656442\n",
    "    Percent Type II errors: 0.18650306748466258\n",
    "    \n",
    "learning_rate=0.05: (lower Type I, higher Type II)\n",
    "    \n",
    "    Percent Type I errors: 0.051533742331288344\n",
    "    Percent Type II errors: 0.19141104294478528\n",
    "    \n",
    "learning_rate=0.2: (higher T1, lower T2)\n",
    "\n",
    "    Percent Type I errors: 0.07607361963190185\n",
    "    Percent Type II errors: 0.18036809815950922\n",
    "    \n",
    "It seems like we're dealing with a trade off here: As we train the model more, Type II goes down but Type I error goes up. This would be a good time to decide which type of error we're more comfortable with.\n",
    "\n",
    "min_samples_split=20: (prevents splits with very little information -- T1 decrease) New Baseline.\n",
    "\n",
    "    Percent Type I errors: 0.05889570552147239\n",
    "    Percent Type II errors: 0.18159509202453988\n",
    "    \n",
    "subsample=0.8: (got worse, varies each time you run it)\n",
    "\n",
    "    Percent Type I errors: 0.0638036809815951\n",
    "    Percent Type II errors: 0.18773006134969325\n",
    "    \n",
    "So far the best thing has been adding more features. Let's try some more of that. (Got a little bit worst again)\n",
    "\n",
    "    Percent Type I errors: 0.06012269938650307\n",
    "    Percent Type II errors: 0.18527607361963191\n",
    "    \n",
    "Okay. What if we change she size of the test set? Offset = 0.8:\n",
    "\n",
    "    Percent Type I errors: 0.11901840490797547\n",
    "    Percent Type II errors: 0.14539877300613496\n",
    "    \n",
    "Now that actually did something! We converted a substantial portion of our T2 error to T1 error. Total error increased slightly, but at least something happened. But decreasing it further brings us back to the same realm we were in before. Weird. Offset = 0.7: \n",
    "\n",
    "    Percent Type I errors: 0.05603271983640082\n",
    "    Percent Type II errors: 0.19222903885480572\n",
    "    \n",
    "I'm running out of ideas for changes to make...\n",
    "\n",
    "Maybe this is the best we can do? I could try endless combinations of these parameters, but what seems to be happening is that every time I decrease T2 error by a little bit, it comes at the expense of a larger increase in T1 error. Which basically means, in order to correctly classify 10 more points, we'll misclassify another 20. The tiny improvements we got were from shuffling the dataset, adding a couple highly effective features, and increasing the min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAEWCAYAAACdTYAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXdNhSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1094f7390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gridsearchCV goes through lots of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_search = [{'n_estimators': [300, 500, 700],\n",
    "          'max_depth': [2, 3],\n",
    "          'loss': ['deviance'],\n",
    "          'learning_rate': [0.03, 0.1, 0.3],\n",
    "          'min_samples_split': [2, 20],\n",
    "          'subsample':[.9, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(ensemble.GradientBoostingClassifier(), param_grid=param_search, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [300, 500, 700], 'max_depth': [2, 3], 'loss': ['deviance'], 'learning_rate': [0.03, 0.1, 0.3], 'min_samples_split': [2, 20], 'subsample': [0.9, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75641025641025639"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 2,\n",
       " 'min_samples_split': 20,\n",
       " 'n_estimators': 700,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.046917621385706494\n",
      "Percent Type II errors: 0.18466993998908893\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.053987730061349694\n",
      "Percent Type II errors: 0.17668711656441718\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! It found a slightly different best_params than I did. This will make everything a lot easier! I could have used a larger grid, but these values made sense based on the exploration I had done, and every additional parameter choice significantly bumps up processing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
