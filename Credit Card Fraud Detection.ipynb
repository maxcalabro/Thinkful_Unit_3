{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Credit Card Fraud With Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 284807)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_data['Class']==1).sum(), len(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest hurdle here is likely to be the class imbalance. Fewer than 500 of the 284,000 records are fraudulent. We can try a few things to make this work. Let's start by resampling the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284807, 30), (284807,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full = raw_data.loc[:, ~raw_data.columns.isin(['Class'])]\n",
    "Y_full = raw_data['Class']\n",
    "X_full.shape, Y_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492, 31), (284315, 31))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pos = raw_data[raw_data['Class']==1]\n",
    "data_neg = raw_data[raw_data['Class']==0]\n",
    "\n",
    "data_pos.shape, data_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214662</th>\n",
       "      <td>139767.0</td>\n",
       "      <td>0.467992</td>\n",
       "      <td>1.100118</td>\n",
       "      <td>-5.607145</td>\n",
       "      <td>2.204714</td>\n",
       "      <td>-0.578539</td>\n",
       "      <td>-0.174200</td>\n",
       "      <td>-3.454201</td>\n",
       "      <td>1.102823</td>\n",
       "      <td>-1.065016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983481</td>\n",
       "      <td>0.899876</td>\n",
       "      <td>-0.285103</td>\n",
       "      <td>-1.929717</td>\n",
       "      <td>0.319869</td>\n",
       "      <td>0.170636</td>\n",
       "      <td>0.851798</td>\n",
       "      <td>0.372098</td>\n",
       "      <td>120.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>20332.0</td>\n",
       "      <td>-15.271362</td>\n",
       "      <td>8.326581</td>\n",
       "      <td>-22.338591</td>\n",
       "      <td>11.885313</td>\n",
       "      <td>-8.721334</td>\n",
       "      <td>-2.324307</td>\n",
       "      <td>-16.196419</td>\n",
       "      <td>0.512882</td>\n",
       "      <td>-6.333685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.356896</td>\n",
       "      <td>1.068019</td>\n",
       "      <td>1.085617</td>\n",
       "      <td>-1.039797</td>\n",
       "      <td>-0.182006</td>\n",
       "      <td>0.649921</td>\n",
       "      <td>2.149247</td>\n",
       "      <td>-1.406811</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154371</th>\n",
       "      <td>101313.0</td>\n",
       "      <td>-25.825982</td>\n",
       "      <td>19.167239</td>\n",
       "      <td>-25.390229</td>\n",
       "      <td>11.125435</td>\n",
       "      <td>-16.682644</td>\n",
       "      <td>3.933699</td>\n",
       "      <td>-37.060311</td>\n",
       "      <td>-28.759799</td>\n",
       "      <td>-11.126624</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.922016</td>\n",
       "      <td>5.703684</td>\n",
       "      <td>3.510019</td>\n",
       "      <td>0.054330</td>\n",
       "      <td>-0.671983</td>\n",
       "      <td>-0.209431</td>\n",
       "      <td>-4.950022</td>\n",
       "      <td>-0.448413</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233258</th>\n",
       "      <td>147501.0</td>\n",
       "      <td>-1.611877</td>\n",
       "      <td>-0.408410</td>\n",
       "      <td>-3.829762</td>\n",
       "      <td>6.249462</td>\n",
       "      <td>-3.360922</td>\n",
       "      <td>1.147964</td>\n",
       "      <td>1.858425</td>\n",
       "      <td>0.474858</td>\n",
       "      <td>-3.838399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245582</td>\n",
       "      <td>0.616383</td>\n",
       "      <td>2.251439</td>\n",
       "      <td>-0.066096</td>\n",
       "      <td>0.538710</td>\n",
       "      <td>0.541325</td>\n",
       "      <td>-0.136243</td>\n",
       "      <td>-0.009852</td>\n",
       "      <td>996.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172787</th>\n",
       "      <td>121238.0</td>\n",
       "      <td>-2.628922</td>\n",
       "      <td>2.275636</td>\n",
       "      <td>-3.745369</td>\n",
       "      <td>1.226948</td>\n",
       "      <td>-1.132966</td>\n",
       "      <td>-1.256353</td>\n",
       "      <td>-1.752420</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>-1.792343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870730</td>\n",
       "      <td>1.269473</td>\n",
       "      <td>-0.265494</td>\n",
       "      <td>-0.480549</td>\n",
       "      <td>0.169665</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>0.070036</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>144.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "214662  139767.0   0.467992   1.100118  -5.607145   2.204714  -0.578539   \n",
       "11841    20332.0 -15.271362   8.326581 -22.338591  11.885313  -8.721334   \n",
       "154371  101313.0 -25.825982  19.167239 -25.390229  11.125435 -16.682644   \n",
       "233258  147501.0  -1.611877  -0.408410  -3.829762   6.249462  -3.360922   \n",
       "172787  121238.0  -2.628922   2.275636  -3.745369   1.226948  -1.132966   \n",
       "\n",
       "              V6         V7         V8         V9  ...          V21       V22  \\\n",
       "214662 -0.174200  -3.454201   1.102823  -1.065016  ...     0.983481  0.899876   \n",
       "11841  -2.324307 -16.196419   0.512882  -6.333685  ...    -2.356896  1.068019   \n",
       "154371  3.933699 -37.060311 -28.759799 -11.126624  ...   -16.922016  5.703684   \n",
       "233258  1.147964   1.858425   0.474858  -3.838399  ...     1.245582  0.616383   \n",
       "172787 -1.256353  -1.752420   0.281736  -1.792343  ...     0.870730  1.269473   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "214662 -0.285103 -1.929717  0.319869  0.170636  0.851798  0.372098  120.54   \n",
       "11841   1.085617 -1.039797 -0.182006  0.649921  2.149247 -1.406811    1.00   \n",
       "154371  3.510019  0.054330 -0.671983 -0.209431 -4.950022 -0.448413    2.28   \n",
       "233258  2.251439 -0.066096  0.538710  0.541325 -0.136243 -0.009852  996.27   \n",
       "172787 -0.265494 -0.480549  0.169665  0.096081  0.070036  0.063768  144.62   \n",
       "\n",
       "        Class  \n",
       "214662      1  \n",
       "11841       1  \n",
       "154371      1  \n",
       "233258      1  \n",
       "172787      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pos_resamp = resample(data_pos, n_samples=20000)\n",
    "data_neg_resamp = resample(data_neg, n_samples=20000)\n",
    "\n",
    "data_resamp = pd.concat([data_pos_resamp, data_neg_resamp])\n",
    "data_resamp = data_resamp.sample(frac=1)\n",
    "\n",
    "data_resamp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try running some models on it. The features of this data set are the result of a PCA, so they should already be orthagonal to each other. We may find it useful to run some feature selection, but for now let's use them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 30), (40000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_resamp.loc[:, ~data_resamp.columns.isin(['Class'])]\n",
    "Y = data_resamp['Class']\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.902   ,  0.91025 ,  0.908625,  0.90825 ,  0.902875])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "cross_val_score(bnb, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97075 ,  0.982625,  0.983375,  0.979   ,  0.97575 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(\n",
    "        max_depth=10,\n",
    "        max_features=4\n",
    ")\n",
    "\n",
    "cross_val_score(dtc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.960875,  0.96225 ,  0.964375,  0.96125 ,  0.96075 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        max_depth=6\n",
    ")\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree runs a lot faster than Random Forest, and is doing just as well at the moment. Let's fit it and see what it does on the actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[279637,   4678],\n",
       "       [    12,    480]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X, Y)\n",
    "\n",
    "Y_pred = dtc.predict(X_full)\n",
    "\n",
    "confusion_matrix(Y_full, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, this is actually pretty great! (Also, I realize confusion matrix isn't the best way to asses this result). But let's just take a really quick look at it. In fraud detection, we are WAY more concerned about missing fraud than we are about mis-classifying non-fraud. And even with this incredibly simple model, we only missed 4 of the 492 examples of fraud. We also sent 5,000 emails alerting people of potential fraud that didn't happen, but hey, they can just confirm that it wasn't fraud, right? One problem here is that we fit on the entire set of positive examples, so we're prone to overfitting. It's a shame we have so few examples, but we really do have to pull some of those out to act as a test set.\n",
    "\n",
    "Let's try this again, but holding out some of the original data to act as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 30), (40000,), (264465, 30), (264465,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate out n_test positive examples for the test set. 150 (30%) seems to give the most stable results.\n",
    "n_test=150\n",
    "\n",
    "data_pos = data_pos.sample(frac=1)\n",
    "data_pos_train = data_pos[n_test:]\n",
    "data_pos_test = data_pos[:n_test]\n",
    "\n",
    "# Separate out 20000 negative examples for training set\n",
    "data_neg = data_neg.sample(frac=1)\n",
    "data_neg_train = data_neg[:20000]\n",
    "data_neg_test = data_neg[20000:]\n",
    "\n",
    "# Upsample the positive training examples so we're back to our 1:1 ratio\n",
    "data_pos_train_resamp = resample(data_pos_train, n_samples=20000)\n",
    "\n",
    "# Recombine to make training and test datasets. Test set now only has 100 positive examples.\n",
    "data_train = pd.concat([data_pos_train_resamp, data_neg_train]).sample(frac=1)\n",
    "data_test = pd.concat([data_pos_test, data_neg_test]).sample(frac=1)\n",
    "\n",
    "X_train = data_train.loc[:, ~data_train.columns.isin(['Class'])]\n",
    "Y_train = data_train['Class']\n",
    "X_test = data_test.loc[:, ~data_test.columns.isin(['Class'])]\n",
    "Y_test = data_test['Class']\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97725 ,  0.989125,  0.9925  ,  0.9865  ,  0.99175 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(\n",
    "        max_depth=10,\n",
    "        max_features=4\n",
    ")\n",
    "\n",
    "cross_val_score(dtc, X_train, Y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[261986,   2329],\n",
       "       [    31,    119]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train,Y_train)\n",
    "Y_pred = dtc.predict(X_test)\n",
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we didn't do quite as well here, but we're still doing something at least! Classified over 80% of the positive examples correctly, while getting better than 98% accuracy on negative examples. Let's take a look at the area under the precision-recall curve (AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42046364830884991"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)\n",
    "auc(precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can do better. First, how does our original result compare to this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auprc(Y, Y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(Y, Y_pred)\n",
    "    return auc(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53894141354577974"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auprc(Y_full, dtc.predict(X_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is with 99% accuracy on positive examples, so doing better will mean fewer false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC: 0.712763972445\n",
      "[[264223     92]\n",
      " [    23    127]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "        n_estimators=30,\n",
    "        max_depth=20,\n",
    "        \n",
    ")\n",
    "\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this is amazing! Using Random Forest, we still aren't getting some of those positives in the test set, but we've reduced false positives to barely any. Let's see how an SVC does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC: 0.411925396555\n",
      "[[264313      2]\n",
      " [   143      7]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1)\n",
    "\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print('AUPRC: ' + str(auprc(Y_test, Y_pred)))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, that takes so much longer to run than random forest and didn't do anything. I don't even want to bother tuning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
